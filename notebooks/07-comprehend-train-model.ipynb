{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Amazon Comprehend Custom Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that Amazon Comprehend is currently only supported in a subset of regions: \n",
    "\n",
    "* US East (N. Virginia), US East (Ohio), US West (Oregon)\n",
    "* Canada (Central)\n",
    "* Europe (London), Europe (Ireland), Europe (Frankfurt)\n",
    "* Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney)\n",
    "\n",
    "You can check https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/ for details and updates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dependencies setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:42:12.351207Z",
     "iopub.status.busy": "2022-11-07T19:42:12.350892Z",
     "iopub.status.idle": "2022-11-07T19:42:12.383673Z",
     "shell.execute_reply": "2022-11-07T19:42:12.377841Z",
     "shell.execute_reply.started": "2022-11-07T19:42:12.351184Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Everything is correctly set up\n"
     ]
    }
   ],
   "source": [
    "%store -r setup_dependencies_passed\n",
    "%store -r comprehend_train_s3_uri\n",
    "\n",
    "try:\n",
    "    setup_dependencies_passed\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE PREVIOUS NOTEBOOK \")\n",
    "    print(\"You did not install the required libraries.   \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "if not setup_dependencies_passed:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE PREVIOUS NOTEBOOK \")\n",
    "    print(\"You did not install the required libraries.   \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "if not comprehend_train_s3_uri:\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"**************** PLEASE RE-RUN THE PREVIOUS DATA PREPARATION NOTEBOOK ******************\")\n",
    "    print(\"**************** THIS NOTEBOOK WILL NOT RUN PROPERLY ***********************************\")\n",
    "    print(\"****************************************************************************************\")\n",
    "else:\n",
    "    print(\"[OK] Everything is correctly set up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:42:18.648072Z",
     "iopub.status.busy": "2022-11-07T19:42:18.647786Z",
     "iopub.status.idle": "2022-11-07T19:42:19.363311Z",
     "shell.execute_reply": "2022-11-07T19:42:19.362444Z",
     "shell.execute_reply.started": "2022-11-07T19:42:18.648050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-15 18:57:23     411440 amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $comprehend_train_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:46:47.342864Z",
     "iopub.status.busy": "2022-11-07T19:46:47.342421Z",
     "iopub.status.idle": "2022-11-07T19:46:47.906054Z",
     "shell.execute_reply": "2022-11-07T19:46:47.905343Z",
     "shell.execute_reply.started": "2022-11-07T19:46:47.342825Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sm = sagemaker.Session()\n",
    "bucket = sm.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if you current regions supports Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:40:45.542220Z",
     "iopub.status.busy": "2022-11-07T19:40:45.541915Z",
     "iopub.status.idle": "2022-11-07T19:40:45.548025Z",
     "shell.execute_reply": "2022-11-07T19:40:45.546940Z",
     "shell.execute_reply.started": "2022-11-07T19:40:45.542193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [OK] COMPREHEND IS SUPPORTED IN us-east-1\n",
      " [OK] Please proceed with this notebook.\n"
     ]
    }
   ],
   "source": [
    "if region in [\n",
    "    \"ap-south-1\",\n",
    "    \"eu-west-2\",\n",
    "    \"eu-west-1\",\n",
    "    \"ap-northeast-2\",\n",
    "    \"ap-northeast-1\",\n",
    "    \"ca-central-1\",\n",
    "    \"ap-southeast-1\",\n",
    "    \"ap-southeast-2\",\n",
    "    \"eu-central-1\",\n",
    "    \"us-east-1\",\n",
    "    \"us-east-2\",\n",
    "    \"us-west-2\",\n",
    "]:\n",
    "    print(\" [OK] COMPREHEND IS SUPPORTED IN {}\".format(region))\n",
    "    print(\" [OK] Please proceed with this notebook.\")\n",
    "else:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\" [ERROR] COMPREHEND IS NOT YET SUPPORTED IN {}.\".format(region))\n",
    "    print(\" [INFO] This is OK. Skip this notebook and continue with the next use case.\")\n",
    "    print(\" [INFO] This notebook is not required for the rest of this workshop.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:41:18.426073Z",
     "iopub.status.busy": "2022-11-07T19:41:18.425727Z",
     "iopub.status.idle": "2022-11-07T19:41:18.444208Z",
     "shell.execute_reply": "2022-11-07T19:41:18.443633Z",
     "shell.execute_reply.started": "2022-11-07T19:41:18.426047Z"
    }
   },
   "outputs": [],
   "source": [
    "comprehend = boto3.client(\"comprehend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our prepared training data which we use as input for Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:43:43.602197Z",
     "iopub.status.busy": "2022-11-07T19:43:43.601274Z",
     "iopub.status.idle": "2022-11-07T19:43:44.647044Z",
     "shell.execute_reply": "2022-11-07T19:43:44.646290Z",
     "shell.execute_reply.started": "2022-11-07T19:43:43.602148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-688013747199/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv to tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $comprehend_train_s3_uri ./tmp/\n",
    "\n",
    "temp_folder = \"tmp\"\n",
    "dataset_csv = \"amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:43:48.830240Z",
     "iopub.status.busy": "2022-11-07T19:43:48.829374Z",
     "iopub.status.idle": "2022-11-07T19:43:49.048509Z",
     "shell.execute_reply": "2022-11-07T19:43:49.044320Z",
     "shell.execute_reply.started": "2022-11-07T19:43:48.830195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Download was quick and easy. I've only had it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>I have been using Quicken Essentials for Mac a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Wish there was a zero star rating.  I had Offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Those of you experimenting with Windows 8 rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the State download was hard to install it keep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  5  Download was quick and easy. I've only had it ...\n",
       "1  3  I have been using Quicken Essentials for Mac a...\n",
       "2  1  Wish there was a zero star rating.  I had Offi...\n",
       "3  1  Those of you experimenting with Windows 8 rele...\n",
       "4  2  the State download was hard to install it keep..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Access Role for Comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:44:48.480675Z",
     "iopub.status.busy": "2022-11-07T19:44:48.480169Z",
     "iopub.status.idle": "2022-11-07T19:44:48.488815Z",
     "shell.execute_reply": "2022-11-07T19:44:48.488136Z",
     "shell.execute_reply.started": "2022-11-07T19:44:48.480636Z"
    }
   },
   "outputs": [],
   "source": [
    "assume_role_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"comprehend.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Role and Attach Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:46:15.741573Z",
     "iopub.status.busy": "2022-11-07T19:46:15.741257Z",
     "iopub.status.idle": "2022-11-07T19:46:15.748646Z",
     "shell.execute_reply": "2022-11-07T19:46:15.747991Z",
     "shell.execute_reply.started": "2022-11-07T19:46:15.741551Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_comprehend_role_name = \"DSOAWS_Comprehend\"\n",
    "iam_comprehend_role_description=\"Curso MLOps Comprehend Role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:46:51.733930Z",
     "iopub.status.busy": "2022-11-07T19:46:51.733641Z",
     "iopub.status.idle": "2022-11-07T19:46:51.875461Z",
     "shell.execute_reply": "2022-11-07T19:46:51.874290Z",
     "shell.execute_reply.started": "2022-11-07T19:46:51.733908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    iam_role_comprehend = iam.create_role(\n",
    "        RoleName=iam_comprehend_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "        Description=iam_comprehend_role_description,\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "        iam_role_comprehend = iam.get_role(RoleName=iam_comprehend_role_name)\n",
    "        print(\"Role already exists\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:48:37.180721Z",
     "iopub.status.busy": "2022-11-07T19:48:37.180305Z",
     "iopub.status.idle": "2022-11-07T19:48:37.187192Z",
     "shell.execute_reply": "2022-11-07T19:48:37.186233Z",
     "shell.execute_reply.started": "2022-11-07T19:48:37.180693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comprehend_s3_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Action\": [\"s3:GetObject\"],\n",
    "            \"Resource\": [f\"arn:aws:s3:::{bucket}/*\"],\n",
    "            \"Effect\": \"Allow\"\n",
    "        },\n",
    "        {\n",
    "            \"Action\": [\"s3:ListBucket\"],\n",
    "            \"Resource\": [f\"arn:aws:s3:::{bucket}\"],\n",
    "            \"Effect\": \"Allow\"\n",
    "        },\n",
    "        {\n",
    "            \"Action\": [\"s3:PutObject\"],\n",
    "            \"Resource\": [f\"arn:aws:s3:::{bucket}/*\"],\n",
    "            \"Effect\": \"Allow\"\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Policy to Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:48:44.702772Z",
     "iopub.status.busy": "2022-11-07T19:48:44.702214Z",
     "iopub.status.idle": "2022-11-07T19:48:44.810501Z",
     "shell.execute_reply": "2022-11-07T19:48:44.809647Z",
     "shell.execute_reply.started": "2022-11-07T19:48:44.702742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '6dd1aa17-be56-4db8-85a2-1f9c0c5bad77', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6dd1aa17-be56-4db8-85a2-1f9c0c5bad77', 'content-type': 'text/xml', 'content-length': '206', 'date': 'Tue, 15 Nov 2022 19:00:46 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = iam.put_role_policy(\n",
    "    RoleName=iam_comprehend_role_name,\n",
    "    PolicyName=\"DSOAWS_ComprehendPolicyToS3\",\n",
    "    PolicyDocument=json.dumps(comprehend_s3_policy_doc),\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:50:01.914867Z",
     "iopub.status.busy": "2022-11-07T19:50:01.914562Z",
     "iopub.status.idle": "2022-11-07T19:50:01.925070Z",
     "shell.execute_reply": "2022-11-07T19:50:01.923770Z",
     "shell.execute_reply.started": "2022-11-07T19:50:01.914843Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-688013747199/models/comprehend/output\n"
     ]
    }
   ],
   "source": [
    "prefix = \"models\"\n",
    "key = \"comprehend/output\"\n",
    "\n",
    "s3_output_job = f\"s3://{bucket}/{prefix}/{key}\"\n",
    "print(s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:50:11.776121Z",
     "iopub.status.busy": "2022-11-07T19:50:11.775833Z",
     "iopub.status.idle": "2022-11-07T19:50:11.780231Z",
     "shell.execute_reply": "2022-11-07T19:50:11.779334Z",
     "shell.execute_reply.started": "2022-11-07T19:50:11.776100Z"
    }
   },
   "outputs": [],
   "source": [
    "iam_role_comprehend_arn = iam_role_comprehend[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:50:39.807148Z",
     "iopub.status.busy": "2022-11-07T19:50:39.806745Z",
     "iopub.status.idle": "2022-11-07T19:50:39.816135Z",
     "shell.execute_reply": "2022-11-07T19:50:39.815054Z",
     "shell.execute_reply.started": "2022-11-07T19:50:39.807118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "comprehend_training_job_name = f\"Amazon-Customer-Reviews-Classifier-{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:53:05.903071Z",
     "iopub.status.busy": "2022-11-07T19:53:05.902653Z",
     "iopub.status.idle": "2022-11-07T19:53:05.908390Z",
     "shell.execute_reply": "2022-11-07T19:53:05.907379Z",
     "shell.execute_reply.started": "2022-11-07T19:53:05.902919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-Customer-Reviews-Classifier-1668541045\n",
      "arn:aws:iam::688013747199:role/DSOAWS_Comprehend\n",
      "s3://sagemaker-us-east-1-688013747199/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n",
      "s3://sagemaker-us-east-1-688013747199/models/comprehend/output\n"
     ]
    }
   ],
   "source": [
    "print(comprehend_training_job_name)\n",
    "print(iam_role_comprehend_arn)\n",
    "print(comprehend_train_s3_uri)\n",
    "print(s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:53:11.463182Z",
     "iopub.status.busy": "2022-11-07T19:53:11.462867Z",
     "iopub.status.idle": "2022-11-07T19:53:11.702818Z",
     "shell.execute_reply": "2022-11-07T19:53:11.701969Z",
     "shell.execute_reply.started": "2022-11-07T19:53:11.463158Z"
    }
   },
   "outputs": [],
   "source": [
    "training_job = comprehend.create_document_classifier(\n",
    "    DocumentClassifierName=comprehend_training_job_name,\n",
    "    DataAccessRoleArn=iam_role_comprehend_arn,\n",
    "    InputDataConfig={\"S3Uri\": comprehend_train_s3_uri},\n",
    "    OutputDataConfig={\"S3Uri\": s3_output_job},\n",
    "    LanguageCode=\"en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:53:23.620272Z",
     "iopub.status.busy": "2022-11-07T19:53:23.619981Z",
     "iopub.status.idle": "2022-11-07T19:53:23.641825Z",
     "shell.execute_reply": "2022-11-07T19:53:23.640807Z",
     "shell.execute_reply.started": "2022-11-07T19:53:23.620249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:688013747199:document-classifier/Amazon-Customer-Reviews-Classifier-1668541045\n"
     ]
    }
   ],
   "source": [
    "comprehend_training_job_arn = training_job[\"DocumentClassifierArn\"]\n",
    "\n",
    "print(comprehend_training_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:53:56.970412Z",
     "iopub.status.busy": "2022-11-07T19:53:56.969909Z",
     "iopub.status.idle": "2022-11-07T19:53:56.980018Z",
     "shell.execute_reply": "2022-11-07T19:53:56.977075Z",
     "shell.execute_reply.started": "2022-11-07T19:53:56.970378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classifier-details/arn:aws:comprehend:us-east-1:688013747199:document-classifier/Amazon-Customer-Reviews-Classifier-1668541045\">Comprehend Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region={}#classifier-details/{}\">Comprehend Training Job</a></b>'.format(\n",
    "            region, comprehend_training_job_arn\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Next Cell Will Take Some Time\n",
    "# _Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_document_classifier in module botocore.client:\n",
      "\n",
      "create_document_classifier(*args, **kwargs) method of botocore.client.Comprehend instance\n",
      "    Creates a new document classifier that you can use to categorize documents. To create a classifier, you provide a set of training documents that labeled with the categories that you want to use. After the classifier is trained you can use it to categorize a set of labeled documents into the categories. For more information, see `Document Classification <https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html>`__ in the Comprehend Developer Guide. \n",
      "    \n",
      "    \n",
      "    \n",
      "    See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/comprehend-2017-11-27/CreateDocumentClassifier>`_\n",
      "    \n",
      "    \n",
      "    **Request Syntax** \n",
      "    ::\n",
      "    \n",
      "      response = client.create_document_classifier(\n",
      "          DocumentClassifierName='string',\n",
      "          VersionName='string',\n",
      "          DataAccessRoleArn='string',\n",
      "          Tags=[\n",
      "              {\n",
      "                  'Key': 'string',\n",
      "                  'Value': 'string'\n",
      "              },\n",
      "          ],\n",
      "          InputDataConfig={\n",
      "              'DataFormat': 'COMPREHEND_CSV'|'AUGMENTED_MANIFEST',\n",
      "              'S3Uri': 'string',\n",
      "              'TestS3Uri': 'string',\n",
      "              'LabelDelimiter': 'string',\n",
      "              'AugmentedManifests': [\n",
      "                  {\n",
      "                      'S3Uri': 'string',\n",
      "                      'Split': 'TRAIN'|'TEST',\n",
      "                      'AttributeNames': [\n",
      "                          'string',\n",
      "                      ],\n",
      "                      'AnnotationDataS3Uri': 'string',\n",
      "                      'SourceDocumentsS3Uri': 'string',\n",
      "                      'DocumentType': 'PLAIN_TEXT_DOCUMENT'|'SEMI_STRUCTURED_DOCUMENT'\n",
      "                  },\n",
      "              ]\n",
      "          },\n",
      "          OutputDataConfig={\n",
      "              'S3Uri': 'string',\n",
      "              'KmsKeyId': 'string'\n",
      "          },\n",
      "          ClientRequestToken='string',\n",
      "          LanguageCode='en'|'es'|'fr'|'de'|'it'|'pt'|'ar'|'hi'|'ja'|'ko'|'zh'|'zh-TW',\n",
      "          VolumeKmsKeyId='string',\n",
      "          VpcConfig={\n",
      "              'SecurityGroupIds': [\n",
      "                  'string',\n",
      "              ],\n",
      "              'Subnets': [\n",
      "                  'string',\n",
      "              ]\n",
      "          },\n",
      "          Mode='MULTI_CLASS'|'MULTI_LABEL',\n",
      "          ModelKmsKeyId='string',\n",
      "          ModelPolicy='string'\n",
      "      )\n",
      "    :type DocumentClassifierName: string\n",
      "    :param DocumentClassifierName: **[REQUIRED]** \n",
      "    \n",
      "      The name of the document classifier.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type VersionName: string\n",
      "    :param VersionName: \n",
      "    \n",
      "      The version name given to the newly created classifier. Version names can have a maximum of 256 characters. Alphanumeric characters, hyphens (-) and underscores (_) are allowed. The version name must be unique among all models with the same classifier name in the account/AWS Region.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type DataAccessRoleArn: string\n",
      "    :param DataAccessRoleArn: **[REQUIRED]** \n",
      "    \n",
      "      The Amazon Resource Name (ARN) of the AWS Identity and Management (IAM) role that grants Amazon Comprehend read access to your input data.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type Tags: list\n",
      "    :param Tags: \n",
      "    \n",
      "      Tags to be associated with the document classifier being created. A tag is a key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with \"Sales\" as the key might be added to a resource to indicate its use by the sales department. \n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "      - *(dict) --* \n",
      "    \n",
      "        A key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with the key-value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by a particular department. \n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "        - **Key** *(string) --* **[REQUIRED]** \n",
      "    \n",
      "          The initial part of a key-value pair that forms a tag associated with a given resource. For instance, if you want to show which resources are used by which departments, you might use “Department” as the key portion of the pair, with multiple possible values such as “sales,” “legal,” and “administration.” \n",
      "    \n",
      "          \n",
      "    \n",
      "        \n",
      "        - **Value** *(string) --* \n",
      "    \n",
      "          The second part of a key-value pair that forms a tag associated with a given resource. For instance, if you want to show which resources are used by which departments, you might use “Department” as the initial (key) portion of the pair, with a value of “sales” to indicate the sales department. \n",
      "    \n",
      "          \n",
      "    \n",
      "        \n",
      "      \n",
      "    \n",
      "    :type InputDataConfig: dict\n",
      "    :param InputDataConfig: **[REQUIRED]** \n",
      "    \n",
      "      Specifies the format and location of the input data for the job.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "      - **DataFormat** *(string) --* \n",
      "    \n",
      "        The format of your training data:\n",
      "    \n",
      "         \n",
      "    \n",
      "         \n",
      "        * ``COMPREHEND_CSV`` : A two-column CSV file, where labels are provided in the first column, and documents are provided in the second. If you use this value, you must provide the ``S3Uri`` parameter in your request. \n",
      "         \n",
      "        * ``AUGMENTED_MANIFEST`` : A labeled dataset that is produced by Amazon SageMaker Ground Truth. This file is in JSON lines format. Each line is a complete JSON object that contains a training document and its associated labels.  If you use this value, you must provide the ``AugmentedManifests`` parameter in your request. \n",
      "         \n",
      "    \n",
      "         \n",
      "    \n",
      "        If you don't specify a value, Amazon Comprehend uses ``COMPREHEND_CSV`` as the default.\n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "      - **S3Uri** *(string) --* \n",
      "    \n",
      "        The Amazon S3 URI for the input data. The S3 bucket must be in the same region as the API endpoint that you are calling. The URI can point to a single input file or it can provide the prefix for a collection of input files.\n",
      "    \n",
      "         \n",
      "    \n",
      "        For example, if you use the URI ``S3://bucketName/prefix`` , if the prefix is a single file, Amazon Comprehend uses that file as input. If more than one file begins with the prefix, Amazon Comprehend uses all of them as input.\n",
      "    \n",
      "         \n",
      "    \n",
      "        This parameter is required if you set ``DataFormat`` to ``COMPREHEND_CSV`` .\n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "      - **TestS3Uri** *(string) --* \n",
      "    \n",
      "        This specifies the Amazon S3 location where the test annotations for an entity recognizer are located. The URI must be in the same AWS Region as the API endpoint that you are calling. \n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "      - **LabelDelimiter** *(string) --* \n",
      "    \n",
      "        Indicates the delimiter used to separate each label for training a multi-label classifier. The default delimiter between labels is a pipe (|). You can use a different character as a delimiter (if it's an allowed character) by specifying it under Delimiter for labels. If the training documents use a delimiter other than the default or the delimiter you specify, the labels on that line will be combined to make a single unique label, such as LABELLABELLABEL.\n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "      - **AugmentedManifests** *(list) --* \n",
      "    \n",
      "        A list of augmented manifest files that provide training data for your custom model. An augmented manifest file is a labeled dataset that is produced by Amazon SageMaker Ground Truth.\n",
      "    \n",
      "         \n",
      "    \n",
      "        This parameter is required if you set ``DataFormat`` to ``AUGMENTED_MANIFEST`` .\n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "        - *(dict) --* \n",
      "    \n",
      "          An augmented manifest file that provides training data for your custom model. An augmented manifest file is a labeled dataset that is produced by Amazon SageMaker Ground Truth.\n",
      "    \n",
      "          \n",
      "    \n",
      "        \n",
      "          - **S3Uri** *(string) --* **[REQUIRED]** \n",
      "    \n",
      "            The Amazon S3 location of the augmented manifest file.\n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "          - **Split** *(string) --* \n",
      "    \n",
      "            The purpose of the data you've provided in the augmented manifest. You can either train or test this data. If you don't specify, the default is train.\n",
      "    \n",
      "             \n",
      "    \n",
      "            TRAIN - all of the documents in the manifest will be used for training. If no test documents are provided, Amazon Comprehend will automatically reserve a portion of the training documents for testing.\n",
      "    \n",
      "             \n",
      "    \n",
      "            TEST - all of the documents in the manifest will be used for testing.\n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "          - **AttributeNames** *(list) --* **[REQUIRED]** \n",
      "    \n",
      "            The JSON attribute that contains the annotations for your training documents. The number of attribute names that you specify depends on whether your augmented manifest file is the output of a single labeling job or a chained labeling job.\n",
      "    \n",
      "             \n",
      "    \n",
      "            If your file is the output of a single labeling job, specify the LabelAttributeName key that was used when the job was created in Ground Truth.\n",
      "    \n",
      "             \n",
      "    \n",
      "            If your file is the output of a chained labeling job, specify the LabelAttributeName key for one or more jobs in the chain. Each LabelAttributeName key provides the annotations from an individual job.\n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "            - *(string) --* \n",
      "    \n",
      "            \n",
      "        \n",
      "          - **AnnotationDataS3Uri** *(string) --* \n",
      "    \n",
      "            The S3 prefix to the annotation files that are referred in the augmented manifest file.\n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "          - **SourceDocumentsS3Uri** *(string) --* \n",
      "    \n",
      "            The S3 prefix to the source files (PDFs) that are referred to in the augmented manifest file.\n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "          - **DocumentType** *(string) --* \n",
      "    \n",
      "            The type of augmented manifest. PlainTextDocument or SemiStructuredDocument. If you don't specify, the default is PlainTextDocument. \n",
      "    \n",
      "             \n",
      "    \n",
      "             \n",
      "            * ``PLAIN_TEXT_DOCUMENT`` A document type that represents any unicode text that is encoded in UTF-8. \n",
      "             \n",
      "            * ``SEMI_STRUCTURED_DOCUMENT`` A document type with positional and structural context, like a PDF. For training with Amazon Comprehend, only PDFs are supported. For inference, Amazon Comprehend support PDFs, DOCX and TXT. \n",
      "             \n",
      "    \n",
      "            \n",
      "    \n",
      "          \n",
      "        \n",
      "    \n",
      "    \n",
      "    :type OutputDataConfig: dict\n",
      "    :param OutputDataConfig: \n",
      "    \n",
      "      Enables the addition of output results configuration parameters for custom classifier jobs.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "      - **S3Uri** *(string) --* \n",
      "    \n",
      "        When you use the ``OutputDataConfig`` object while creating a custom classifier, you specify the Amazon S3 location where you want to write the confusion matrix. The URI must be in the same region as the API endpoint that you are calling. The location is used as the prefix for the actual location of this output file.\n",
      "    \n",
      "         \n",
      "    \n",
      "        When the custom classifier job is finished, the service creates the output file in a directory specific to the job. The ``S3Uri`` field contains the location of the output file, called ``output.tar.gz`` . It is a compressed archive that contains the confusion matrix.\n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "      - **KmsKeyId** *(string) --* \n",
      "    \n",
      "        ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt the output results from an analysis job. The KmsKeyId can be one of the following formats:\n",
      "    \n",
      "         \n",
      "    \n",
      "         \n",
      "        * KMS Key ID: ``\"1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "         \n",
      "        * Amazon Resource Name (ARN) of a KMS Key: ``\"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "         \n",
      "        * KMS Key Alias: ``\"alias/ExampleAlias\"``   \n",
      "         \n",
      "        * ARN of a KMS Key Alias: ``\"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias\"``   \n",
      "         \n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "    \n",
      "    :type ClientRequestToken: string\n",
      "    :param ClientRequestToken: \n",
      "    \n",
      "      A unique identifier for the request. If you don't set the client request token, Amazon Comprehend generates one.\n",
      "    \n",
      "      This field is autopopulated if not provided.\n",
      "    \n",
      "    \n",
      "    :type LanguageCode: string\n",
      "    :param LanguageCode: **[REQUIRED]** \n",
      "    \n",
      "      The language of the input documents. You can specify any of the following languages supported by Amazon Comprehend: German (\"de\"), English (\"en\"), Spanish (\"es\"), French (\"fr\"), Italian (\"it\"), or Portuguese (\"pt\"). All documents must be in the same language.\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type VolumeKmsKeyId: string\n",
      "    :param VolumeKmsKeyId: \n",
      "    \n",
      "      ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt data on the storage volume attached to the ML compute instance(s) that process the analysis job. The VolumeKmsKeyId can be either of the following formats:\n",
      "    \n",
      "       \n",
      "    \n",
      "       \n",
      "      * KMS Key ID: ``\"1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "       \n",
      "      * Amazon Resource Name (ARN) of a KMS Key: ``\"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "       \n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type VpcConfig: dict\n",
      "    :param VpcConfig: \n",
      "    \n",
      "      Configuration parameters for an optional private Virtual Private Cloud (VPC) containing the resources you are using for your custom classifier. For more information, see `Amazon VPC <https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html>`__ . \n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "      - **SecurityGroupIds** *(list) --* **[REQUIRED]** \n",
      "    \n",
      "        The ID number for a security group on an instance of your private VPC. Security groups on your VPC function serve as a virtual firewall to control inbound and outbound traffic and provides security for the resources that you’ll be accessing on the VPC. This ID number is preceded by \"sg-\", for instance: \"sg-03b388029b0a285ea\". For more information, see `Security Groups for your VPC <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html>`__ . \n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "        - *(string) --* \n",
      "    \n",
      "        \n",
      "    \n",
      "      - **Subnets** *(list) --* **[REQUIRED]** \n",
      "    \n",
      "        The ID for each subnet being used in your private VPC. This subnet is a subset of the a range of IPv4 addresses used by the VPC and is specific to a given availability zone in the VPC’s region. This ID number is preceded by \"subnet-\", for instance: \"subnet-04ccf456919e69055\". For more information, see `VPCs and Subnets <https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html>`__ . \n",
      "    \n",
      "        \n",
      "    \n",
      "      \n",
      "        - *(string) --* \n",
      "    \n",
      "        \n",
      "    \n",
      "    \n",
      "    :type Mode: string\n",
      "    :param Mode: \n",
      "    \n",
      "      Indicates the mode in which the classifier will be trained. The classifier can be trained in multi-class mode, which identifies one and only one class for each document, or multi-label mode, which identifies one or more labels for each document. In multi-label mode, multiple labels for an individual document are separated by a delimiter. The default delimiter between labels is a pipe (|).\n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type ModelKmsKeyId: string\n",
      "    :param ModelKmsKeyId: \n",
      "    \n",
      "      ID for the AWS Key Management Service (KMS) key that Amazon Comprehend uses to encrypt trained custom models. The ModelKmsKeyId can be either of the following formats:\n",
      "    \n",
      "       \n",
      "    \n",
      "       \n",
      "      * KMS Key ID: ``\"1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "       \n",
      "      * Amazon Resource Name (ARN) of a KMS Key: ``\"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"``   \n",
      "       \n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    :type ModelPolicy: string\n",
      "    :param ModelPolicy: \n",
      "    \n",
      "      The resource-based policy to attach to your custom document classifier model. You can use this policy to allow another AWS account to import your custom model.\n",
      "    \n",
      "       \n",
      "    \n",
      "      Provide your policy as a JSON body that you enter as a UTF-8 encoded string without line breaks. To provide valid JSON, enclose the attribute names and values in double quotes. If the JSON body is also enclosed in double quotes, then you must escape the double quotes that are inside the policy:\n",
      "    \n",
      "       \n",
      "    \n",
      "       ``\"{\\\"attribute\\\": \\\"value\\\", \\\"attribute\\\": [\\\"value\\\"]}\"``  \n",
      "    \n",
      "       \n",
      "    \n",
      "      To avoid escaping quotes, you can use single quotes to enclose the policy and double quotes to enclose the JSON names and values:\n",
      "    \n",
      "       \n",
      "    \n",
      "       ``'{\"attribute\": \"value\", \"attribute\": [\"value\"]}'``  \n",
      "    \n",
      "      \n",
      "    \n",
      "    \n",
      "    \n",
      "    :rtype: dict\n",
      "    :returns: \n",
      "      \n",
      "      **Response Syntax** \n",
      "    \n",
      "      \n",
      "      ::\n",
      "    \n",
      "        {\n",
      "            'DocumentClassifierArn': 'string'\n",
      "        }\n",
      "      **Response Structure** \n",
      "    \n",
      "      \n",
      "    \n",
      "      - *(dict) --* \n",
      "        \n",
      "    \n",
      "        - **DocumentClassifierArn** *(string) --* \n",
      "    \n",
      "          The Amazon Resource Name (ARN) that identifies the document classifier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(comprehend.create_document_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T19:54:39.753130Z",
     "iopub.status.busy": "2022-11-07T19:54:39.752794Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINED\n",
      "\n",
      "Status TRAINED\n",
      "\n",
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:688013747199:document-classifier/Amazon-Customer-Reviews-Classifier-1668541045', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2022, 11, 15, 19, 37, 27, 660000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2022, 11, 15, 20, 19, 58, 944000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2022, 11, 15, 19, 43, 45, 141000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2022, 11, 15, 20, 19, 8, 682000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'S3Uri': 's3://sagemaker-us-east-1-688013747199/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv'}, 'OutputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-688013747199/models/comprehend/output/688013747199-CLR-9bf5224d1052eb06da7255a5f2a7f287/output/output.tar.gz'}, 'ClassifierMetadata': {'NumberOfLabels': 5, 'NumberOfTrainedDocuments': 810, 'NumberOfTestDocuments': 90, 'EvaluationMetrics': {'Accuracy': 0.4111, 'Precision': 0.4354, 'Recall': 0.4111, 'F1Score': 0.412, 'MicroPrecision': 0.4111, 'MicroRecall': 0.4111, 'MicroF1Score': 0.4111, 'HammingLoss': 0.5889}}, 'DataAccessRoleArn': 'arn:aws:iam::688013747199:role/DSOAWS_Comprehend', 'Mode': 'MULTI_CLASS'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "max_time = time.time() + 3 * 60 * 60  # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn=comprehend_training_job_arn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(f\"Custom classifier: {status}\")\n",
    "\n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        print(\"\")\n",
    "        print(f\"Status {status}\")\n",
    "        print(\"\")\n",
    "        print(describe_custom_classifier[\"DocumentClassifierProperties\"])\n",
    "        break\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait Until the ^^ Classifier ^^ is Trained Above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO] _Feel free to continue to the next workshop section while this notebook is running._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:688013747199:document-classifier/Amazon-Customer-Reviews-Classifier-1668541045', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2022, 11, 15, 19, 37, 27, 660000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2022, 11, 15, 20, 19, 58, 944000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2022, 11, 15, 19, 43, 45, 141000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2022, 11, 15, 20, 19, 8, 682000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'S3Uri': 's3://sagemaker-us-east-1-688013747199/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv'}, 'OutputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-688013747199/models/comprehend/output/688013747199-CLR-9bf5224d1052eb06da7255a5f2a7f287/output/output.tar.gz'}, 'ClassifierMetadata': {'NumberOfLabels': 5, 'NumberOfTrainedDocuments': 810, 'NumberOfTestDocuments': 90, 'EvaluationMetrics': {'Accuracy': 0.4111, 'Precision': 0.4354, 'Recall': 0.4111, 'F1Score': 0.412, 'MicroPrecision': 0.4111, 'MicroRecall': 0.4111, 'MicroF1Score': 0.4111, 'HammingLoss': 0.5889}}, 'DataAccessRoleArn': 'arn:aws:iam::688013747199:role/DSOAWS_Comprehend', 'Mode': 'MULTI_CLASS'}\n"
     ]
    }
   ],
   "source": [
    "print(describe_custom_classifier[\"DocumentClassifierProperties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:688013747199:document-classifier/Amazon-Customer-Reviews-Classifier-1668541045\n"
     ]
    }
   ],
   "source": [
    "model_arn = describe_custom_classifier[\"DocumentClassifierProperties\"][\"DocumentClassifierArn\"]\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-688013747199/models/comprehend/output/688013747199-CLR-9bf5224d1052eb06da7255a5f2a7f287/output/output.tar.gz\n",
      "models/comprehend/output/688013747199-CLR-9bf5224d1052eb06da7255a5f2a7f287/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Retrieve the S3URI from the model output and create jobkey variable.\n",
    "job_output = describe_custom_classifier[\"DocumentClassifierProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "print(job_output)\n",
    "\n",
    "path_prefix = \"s3://{}/\".format(bucket)\n",
    "\n",
    "job_key = os.path.relpath(job_output, path_prefix)\n",
    "\n",
    "print(job_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Model Artifacts including Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(bucket).download_file(job_key, f\"{temp_folder}/output.tar.gz\")\n",
    "\n",
    "#s3 = boto3.client(\"s3\")\n",
    "\n",
    "#s3.download_file(\n",
    "#    Bucket=bucket,\n",
    "#    Key=job_key,\n",
    "#    Filename=f\"{temp_folder}/output.tar.gz\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/\n",
      "output/confusion_matrix.json\n"
     ]
    }
   ],
   "source": [
    "# Unpack the gzip file\n",
    "!tar xvzf ./tmp/output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"confusion_matrix\": [\n",
      "    [\n",
      "      7,\n",
      "      4,\n",
      "      2,\n",
      "      5,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      6,\n",
      "      7,\n",
      "      3,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      0,\n",
      "      6,\n",
      "      3,\n",
      "      6,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      5,\n",
      "      3,\n",
      "      7,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      1,\n",
      "      0,\n",
      "      2,\n",
      "      14\n",
      "    ]\n",
      "  ],\n",
      "  \"labels\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\",\n",
      "    \"4\",\n",
      "    \"5\"\n",
      "  ],\n",
      "  \"type\": \"multi_class\",\n",
      "  \"all_labels\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\",\n",
      "    \"4\",\n",
      "    \"5\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./output/confusion_matrix.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(json.dumps(data, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>        </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\"> 5</td><td>(Predicted)</td></tr>\n",
       "<tr><td>1       </td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\"> 0</td><td>           </td></tr>\n",
       "<tr><td>2       </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\"> 1</td><td>           </td></tr>\n",
       "<tr><td>3       </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">6</td><td style=\"text-align: right;\"> 3</td><td>           </td></tr>\n",
       "<tr><td>4       </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\"> 2</td><td>           </td></tr>\n",
       "<tr><td>5       </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">14</td><td>           </td></tr>\n",
       "<tr><td>(Actual)</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">  </td><td>           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "table = [\n",
    "    [\"\", \"1\", \"2\", \"3\", \"4\", \"5\", \"(Predicted)\"],\n",
    "    [\n",
    "        \"1\",\n",
    "        data[\"confusion_matrix\"][0][0],\n",
    "        data[\"confusion_matrix\"][0][1],\n",
    "        data[\"confusion_matrix\"][0][2],\n",
    "        data[\"confusion_matrix\"][0][3],\n",
    "        data[\"confusion_matrix\"][0][4],\n",
    "    ],\n",
    "    [\n",
    "        \"2\",\n",
    "        data[\"confusion_matrix\"][1][0],\n",
    "        data[\"confusion_matrix\"][1][1],\n",
    "        data[\"confusion_matrix\"][1][2],\n",
    "        data[\"confusion_matrix\"][1][3],\n",
    "        data[\"confusion_matrix\"][1][4],\n",
    "    ],\n",
    "    [\n",
    "        \"3\",\n",
    "        data[\"confusion_matrix\"][2][0],\n",
    "        data[\"confusion_matrix\"][2][1],\n",
    "        data[\"confusion_matrix\"][2][2],\n",
    "        data[\"confusion_matrix\"][2][3],\n",
    "        data[\"confusion_matrix\"][2][4],\n",
    "    ],\n",
    "    [\n",
    "        \"4\",\n",
    "        data[\"confusion_matrix\"][3][0],\n",
    "        data[\"confusion_matrix\"][3][1],\n",
    "        data[\"confusion_matrix\"][3][2],\n",
    "        data[\"confusion_matrix\"][3][3],\n",
    "        data[\"confusion_matrix\"][3][4],\n",
    "    ],\n",
    "    [\n",
    "        \"5\",\n",
    "        data[\"confusion_matrix\"][4][0],\n",
    "        data[\"confusion_matrix\"][4][1],\n",
    "        data[\"confusion_matrix\"][4][2],\n",
    "        data[\"confusion_matrix\"][4][3],\n",
    "        data[\"confusion_matrix\"][4][4],\n",
    "    ],\n",
    "    [\"(Actual)\"],\n",
    "]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "comprehend_endpoint_name = \"comprehend-inference-ep-\" + timestamp_suffix\n",
    "\n",
    "inference_endpoint_response = comprehend.create_endpoint(\n",
    "    EndpointName=comprehend_endpoint_name, ModelArn=model_arn, DesiredInferenceUnits=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:688013747199:document-classifier-endpoint/comprehend-inference-ep-15-20-28-20\n"
     ]
    }
   ],
   "source": [
    "comprehend_endpoint_arn = inference_endpoint_response[\"EndpointArn\"]\n",
    "print(comprehend_endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Variables to the Next Notebook(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'comprehend_training_job_arn' (str)\n",
      "Stored 'comprehend_endpoint_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store comprehend_training_job_arn\n",
    "%store comprehend_endpoint_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "    Jupyter.notebook.save_checkpoint();\n",
       "    Jupyter.notebook.session.delete();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
